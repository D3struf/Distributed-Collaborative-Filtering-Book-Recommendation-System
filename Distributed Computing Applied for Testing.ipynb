{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61afba0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\johnp\\.conda\\envs\\tf-new\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\johnp\\.conda\\envs\\tf-new\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d48dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"BookRecommendation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a0a454",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NearestNeighbors' from 'pyspark.ml' (C:\\Users\\johnp\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\ml\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NearestNeighbors\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'NearestNeighbors' from 'pyspark.ml' (C:\\Users\\johnp\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\ml\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c2ce8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PAUL-HERE:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BookRecommendation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1838cf20a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a3bab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the pickle files\n",
    "with open('Exports/book_names.pkl', 'rb') as f:\n",
    "    book_names = pd.read_pickle(f)\n",
    "\n",
    "with open('Exports/book_pivot.pkl', 'rb') as f:\n",
    "    book_pivot = pd.read_pickle(f)\n",
    "\n",
    "with open('Exports/final_rating.pkl', 'rb') as f:\n",
    "    final_rating = pd.read_pickle(f)\n",
    "\n",
    "with open('Exports/model.pkl', 'rb') as f:\n",
    "    model = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7f345c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1984', '1st to Die: A Novel', '2nd Chance', '4 Blondes',\n",
       "       '84 Charing Cross Road', 'A Bend in the Road', 'A Case of Need',\n",
       "       'A Child Called \\It\\\": One Child's Courage to Survive\"',\n",
       "       'A Civil Action', 'A Cry In The Night',\n",
       "       ...\n",
       "       'Winter Solstice', 'Wish You Well', 'Without Remorse',\n",
       "       'Wizard and Glass (The Dark Tower, Book 4)', 'Wuthering Heights',\n",
       "       'Year of Wonders', 'You Belong To Me',\n",
       "       'Zen and the Art of Motorcycle Maintenance: An Inquiry into Values',\n",
       "       'Zoya', '\\O\\\" Is for Outlaw\"'],\n",
       "      dtype='object', name='title', length=742)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e19fb2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1e70306",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_names_df = book_names.to_frame(index=False).reset_index(drop=True)\n",
    "book_names_df.columns = ['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ec75776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f6adb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st to Die: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 Blondes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84 Charing Cross Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Year of Wonders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>You Belong To Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Zen and the Art of Motorcycle Maintenance: An ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Zoya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>\\O\\\" Is for Outlaw\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title\n",
       "0                                                 1984\n",
       "1                                  1st to Die: A Novel\n",
       "2                                           2nd Chance\n",
       "3                                            4 Blondes\n",
       "4                                84 Charing Cross Road\n",
       "..                                                 ...\n",
       "737                                    Year of Wonders\n",
       "738                                   You Belong To Me\n",
       "739  Zen and the Art of Motorcycle Maintenance: An ...\n",
       "740                                               Zoya\n",
       "741                                \\O\\\" Is for Outlaw\"\n",
       "\n",
       "[742 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36bb13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c29d9785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_of_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3363</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>6</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12538</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13552</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/002542730X.0...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236701</th>\n",
       "      <td>255489</td>\n",
       "      <td>0553579983</td>\n",
       "      <td>7</td>\n",
       "      <td>And Then You Die</td>\n",
       "      <td>Iris Johansen</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>http://images.amazon.com/images/P/0553579983.0...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236702</th>\n",
       "      <td>256407</td>\n",
       "      <td>0553579983</td>\n",
       "      <td>0</td>\n",
       "      <td>And Then You Die</td>\n",
       "      <td>Iris Johansen</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>http://images.amazon.com/images/P/0553579983.0...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236703</th>\n",
       "      <td>257204</td>\n",
       "      <td>0553579983</td>\n",
       "      <td>0</td>\n",
       "      <td>And Then You Die</td>\n",
       "      <td>Iris Johansen</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>http://images.amazon.com/images/P/0553579983.0...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236704</th>\n",
       "      <td>261829</td>\n",
       "      <td>0553579983</td>\n",
       "      <td>0</td>\n",
       "      <td>And Then You Die</td>\n",
       "      <td>Iris Johansen</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>http://images.amazon.com/images/P/0553579983.0...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236705</th>\n",
       "      <td>273979</td>\n",
       "      <td>0553579983</td>\n",
       "      <td>0</td>\n",
       "      <td>And Then You Die</td>\n",
       "      <td>Iris Johansen</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>http://images.amazon.com/images/P/0553579983.0...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59850 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        ISBN  rating  \\\n",
       "0        277427  002542730X      10   \n",
       "1          3363  002542730X       0   \n",
       "2         11676  002542730X       6   \n",
       "3         12538  002542730X      10   \n",
       "4         13552  002542730X       0   \n",
       "...         ...         ...     ...   \n",
       "236701   255489  0553579983       7   \n",
       "236702   256407  0553579983       0   \n",
       "236703   257204  0553579983       0   \n",
       "236704   261829  0553579983       0   \n",
       "236705   273979  0553579983       0   \n",
       "\n",
       "                                                    title             author  \\\n",
       "0       Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner   \n",
       "1       Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner   \n",
       "2       Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner   \n",
       "3       Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner   \n",
       "4       Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner   \n",
       "...                                                   ...                ...   \n",
       "236701                                   And Then You Die      Iris Johansen   \n",
       "236702                                   And Then You Die      Iris Johansen   \n",
       "236703                                   And Then You Die      Iris Johansen   \n",
       "236704                                   And Then You Die      Iris Johansen   \n",
       "236705                                   And Then You Die      Iris Johansen   \n",
       "\n",
       "        year                  publisher  \\\n",
       "0       1994  John Wiley &amp; Sons Inc   \n",
       "1       1994  John Wiley &amp; Sons Inc   \n",
       "2       1994  John Wiley &amp; Sons Inc   \n",
       "3       1994  John Wiley &amp; Sons Inc   \n",
       "4       1994  John Wiley &amp; Sons Inc   \n",
       "...      ...                        ...   \n",
       "236701  1998                     Bantam   \n",
       "236702  1998                     Bantam   \n",
       "236703  1998                     Bantam   \n",
       "236704  1998                     Bantam   \n",
       "236705  1998                     Bantam   \n",
       "\n",
       "                                                image_url  num_of_rating  \n",
       "0       http://images.amazon.com/images/P/002542730X.0...             82  \n",
       "1       http://images.amazon.com/images/P/002542730X.0...             82  \n",
       "2       http://images.amazon.com/images/P/002542730X.0...             82  \n",
       "3       http://images.amazon.com/images/P/002542730X.0...             82  \n",
       "4       http://images.amazon.com/images/P/002542730X.0...             82  \n",
       "...                                                   ...            ...  \n",
       "236701  http://images.amazon.com/images/P/0553579983.0...             50  \n",
       "236702  http://images.amazon.com/images/P/0553579983.0...             50  \n",
       "236703  http://images.amazon.com/images/P/0553579983.0...             50  \n",
       "236704  http://images.amazon.com/images/P/0553579983.0...             50  \n",
       "236705  http://images.amazon.com/images/P/0553579983.0...             50  \n",
       "\n",
       "[59850 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35ffd108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge 'book_names' and 'final_rating' to get book_pivot\n",
    "book_pivot = pd.merge(book_names_df, final_rating[['title', 'user_id', 'rating']], on='title', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb12f07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984</td>\n",
       "      <td>254</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>11676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984</td>\n",
       "      <td>12538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>15408</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>16795</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59845</th>\n",
       "      <td>\\O\\\" Is for Outlaw\"</td>\n",
       "      <td>234359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59846</th>\n",
       "      <td>\\O\\\" Is for Outlaw\"</td>\n",
       "      <td>234623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59847</th>\n",
       "      <td>\\O\\\" Is for Outlaw\"</td>\n",
       "      <td>236283</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59848</th>\n",
       "      <td>\\O\\\" Is for Outlaw\"</td>\n",
       "      <td>238120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59849</th>\n",
       "      <td>\\O\\\" Is for Outlaw\"</td>\n",
       "      <td>254899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59850 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title  user_id  rating\n",
       "0                     1984      254       9\n",
       "1                     1984    11676       0\n",
       "2                     1984    12538       0\n",
       "3                     1984    15408       9\n",
       "4                     1984    16795       8\n",
       "...                    ...      ...     ...\n",
       "59845  \\O\\\" Is for Outlaw\"   234359       0\n",
       "59846  \\O\\\" Is for Outlaw\"   234623       0\n",
       "59847  \\O\\\" Is for Outlaw\"   236283      10\n",
       "59848  \\O\\\" Is for Outlaw\"   238120       0\n",
       "59849  \\O\\\" Is for Outlaw\"   254899       0\n",
       "\n",
       "[59850 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d725971f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Assuming book_pivot is a pandas DataFrame\n",
    "book_pivot_spark = spark.createDataFrame(book_pivot.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a32cfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[index: bigint, title: string, user_id: bigint, rating: bigint]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_pivot_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0c63695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49d04320",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[CANNOT_INFER_TYPE_FOR_FIELD] Unable to infer the type of the field `title`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1630\u001b[0m, in \u001b[0;36m_infer_type\u001b[1;34m(obj, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1670\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1671\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_SCHEMA_FOR_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1672\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(row)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   1673\u001b[0m     )\n\u001b[0;32m   1675\u001b[0m fields \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [CANNOT_INFER_SCHEMA_FOR_TYPE] Can not infer schema for type: `ReferenceType`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1681\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1678\u001b[0m     fields\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1679\u001b[0m         StructField(\n\u001b[0;32m   1680\u001b[0m             k,\n\u001b[1;32m-> 1681\u001b[0m             \u001b[43m_infer_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1683\u001b[0m \u001b[43m                \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m                \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1687\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1688\u001b[0m         )\n\u001b[0;32m   1689\u001b[0m     )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1636\u001b[0m, in \u001b[0;36m_infer_type\u001b[1;34m(obj, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1637\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNSUPPORTED_DATA_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1638\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   1639\u001b[0m     )\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [UNSUPPORTED_DATA_TYPE] Unsupported DataType `ReferenceType`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1630\u001b[0m, in \u001b[0;36m_infer_type\u001b[1;34m(obj, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1691\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1691\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1692\u001b[0m             error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_TYPE_FOR_FIELD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1693\u001b[0m             message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: k},\n\u001b[0;32m   1694\u001b[0m         )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructType(fields)\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [CANNOT_INFER_TYPE_FOR_FIELD] Unable to infer the type of the field `_obj`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1681\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1678\u001b[0m     fields\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1679\u001b[0m         StructField(\n\u001b[0;32m   1680\u001b[0m             k,\n\u001b[1;32m-> 1681\u001b[0m             \u001b[43m_infer_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1683\u001b[0m \u001b[43m                \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m                \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1687\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1688\u001b[0m         )\n\u001b[0;32m   1689\u001b[0m     )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1636\u001b[0m, in \u001b[0;36m_infer_type\u001b[1;34m(obj, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1637\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNSUPPORTED_DATA_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1638\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   1639\u001b[0m     )\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [UNSUPPORTED_DATA_TYPE] Unsupported DataType `Flags`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1630\u001b[0m, in \u001b[0;36m_infer_type\u001b[1;34m(obj, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1691\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1691\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1692\u001b[0m             error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_TYPE_FOR_FIELD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1693\u001b[0m             message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: k},\n\u001b[0;32m   1694\u001b[0m         )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructType(fields)\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [CANNOT_INFER_TYPE_FOR_FIELD] Unable to infer the type of the field `_flags`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1681\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1678\u001b[0m     fields\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1679\u001b[0m         StructField(\n\u001b[0;32m   1680\u001b[0m             k,\n\u001b[1;32m-> 1681\u001b[0m             \u001b[43m_infer_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1683\u001b[0m \u001b[43m                \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m                \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1687\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1688\u001b[0m         )\n\u001b[0;32m   1689\u001b[0m     )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1636\u001b[0m, in \u001b[0;36m_infer_type\u001b[1;34m(obj, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1637\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNSUPPORTED_DATA_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1638\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   1639\u001b[0m     )\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [UNSUPPORTED_DATA_TYPE] Unsupported DataType `DataFrame`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming book_name is a string\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m broadcast_book_name \u001b[38;5;241m=\u001b[39m broadcast(\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_names_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\session.py:1443\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[0;32m   1442\u001b[0m     )\n\u001b[1;32m-> 1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\session.py:1485\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1483\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1485\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\session.py:1093\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[1;34m(self, data, schema)\u001b[0m\n\u001b[0;32m   1090\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m-> 1093\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchemaFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[0;32m   1095\u001b[0m     tupled_data: Iterable[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(converter, data)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\session.py:955\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[1;34m(self, data, names)\u001b[0m\n\u001b[0;32m    953\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39mlegacyInferArrayTypeFromFirstElement()\n\u001b[0;32m    954\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[1;32m--> 955\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_merge_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _has_nulltype(schema):\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[0;32m    970\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_DETERMINE_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    971\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    972\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\session.py:958\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    953\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39mlegacyInferArrayTypeFromFirstElement()\n\u001b[0;32m    954\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[0;32m    955\u001b[0m schema \u001b[38;5;241m=\u001b[39m reduce(\n\u001b[0;32m    956\u001b[0m     _merge_type,\n\u001b[0;32m    957\u001b[0m     (\n\u001b[1;32m--> 958\u001b[0m         \u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[0;32m    966\u001b[0m     ),\n\u001b[0;32m    967\u001b[0m )\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _has_nulltype(schema):\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[0;32m    970\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_DETERMINE_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    971\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    972\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-new\\lib\\site-packages\\pyspark\\sql\\types.py:1691\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         fields\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1679\u001b[0m             StructField(\n\u001b[0;32m   1680\u001b[0m                 k,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1688\u001b[0m             )\n\u001b[0;32m   1689\u001b[0m         )\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1691\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1692\u001b[0m             error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_TYPE_FOR_FIELD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1693\u001b[0m             message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: k},\n\u001b[0;32m   1694\u001b[0m         )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructType(fields)\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [CANNOT_INFER_TYPE_FOR_FIELD] Unable to infer the type of the field `title`."
     ]
    }
   ],
   "source": [
    "# Assuming book_name is a string\n",
    "broadcast_book_name = broadcast(spark.createDataFrame([(book_names_df,)], [\"title\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
